{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaaksenova/ResearchSeminar_NN/blob/change/LSTM_attention_BERT_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91f7818f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T07:59:03.925475Z",
          "iopub.status.busy": "2021-12-17T07:59:03.923750Z",
          "iopub.status.idle": "2021-12-17T07:59:58.821746Z",
          "shell.execute_reply": "2021-12-17T07:59:58.821145Z",
          "shell.execute_reply.started": "2021-12-17T07:47:12.799671Z"
        },
        "id": "91f7818f",
        "outputId": "7a354372-12eb-42a9-f7c2-e591aec539f8",
        "papermill": {
          "duration": 54.978924,
          "end_time": "2021-12-17T07:59:58.821934",
          "exception": false,
          "start_time": "2021-12-17T07:59:03.843010",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7d6b80f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T07:59:58.980836Z",
          "iopub.status.busy": "2021-12-17T07:59:58.980146Z",
          "iopub.status.idle": "2021-12-17T08:00:00.618132Z",
          "shell.execute_reply": "2021-12-17T08:00:00.617600Z",
          "shell.execute_reply.started": "2021-12-17T07:48:05.051759Z"
        },
        "id": "7d6b80f4",
        "outputId": "9b329d82-7720-4c15-875c-c14c97d412ea",
        "papermill": {
          "duration": 1.720859,
          "end_time": "2021-12-17T08:00:00.618263",
          "exception": false,
          "start_time": "2021-12-17T07:59:58.897404",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea1b1e6",
      "metadata": {
        "id": "5ea1b1e6",
        "papermill": {
          "duration": 0.074244,
          "end_time": "2021-12-17T08:00:00.766887",
          "exception": false,
          "start_time": "2021-12-17T08:00:00.692643",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6b73bb1f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:00.919898Z",
          "iopub.status.busy": "2021-12-17T08:00:00.919001Z",
          "iopub.status.idle": "2021-12-17T08:00:00.920795Z",
          "shell.execute_reply": "2021-12-17T08:00:00.921303Z",
          "shell.execute_reply.started": "2021-12-17T07:48:06.596929Z"
        },
        "id": "6b73bb1f",
        "papermill": {
          "duration": 0.08079,
          "end_time": "2021-12-17T08:00:00.921443",
          "exception": false,
          "start_time": "2021-12-17T08:00:00.840653",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Добавила сид\n",
        "import random\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24f860b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:01.076536Z",
          "iopub.status.busy": "2021-12-17T08:00:01.075808Z",
          "iopub.status.idle": "2021-12-17T08:00:04.530559Z",
          "shell.execute_reply": "2021-12-17T08:00:04.531064Z",
          "shell.execute_reply.started": "2021-12-17T07:48:06.604152Z"
        },
        "id": "24f860b3",
        "outputId": "62ee017b-d0ef-4662-bf4d-780aea8fd606",
        "papermill": {
          "duration": 3.535336,
          "end_time": "2021-12-17T08:00:04.531239",
          "exception": false,
          "start_time": "2021-12-17T08:00:00.995903",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-17 12:09:24--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   129MB/s    in 0.2s    \n",
            "\n",
            "2021-12-17 12:09:25 (129 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0653a703",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:04.686449Z",
          "iopub.status.busy": "2021-12-17T08:00:04.685673Z",
          "iopub.status.idle": "2021-12-17T08:00:04.687703Z",
          "shell.execute_reply": "2021-12-17T08:00:04.688109Z",
          "shell.execute_reply.started": "2021-12-17T07:48:08.732356Z"
        },
        "id": "0653a703",
        "papermill": {
          "duration": 0.080915,
          "end_time": "2021-12-17T08:00:04.688254",
          "exception": false,
          "start_time": "2021-12-17T08:00:04.607339",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7cd9b728",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:04.843274Z",
          "iopub.status.busy": "2021-12-17T08:00:04.842452Z",
          "iopub.status.idle": "2021-12-17T08:00:05.499151Z",
          "shell.execute_reply": "2021-12-17T08:00:05.498594Z",
          "shell.execute_reply.started": "2021-12-17T07:48:08.739290Z"
        },
        "id": "7cd9b728",
        "outputId": "1f7270fb-4506-403d-fbde-0f4abca9a87b",
        "papermill": {
          "duration": 0.73609,
          "end_time": "2021-12-17T08:00:05.499299",
          "exception": false,
          "start_time": "2021-12-17T08:00:04.763209",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec 17 12:09 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d1c96e52",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:05.669331Z",
          "iopub.status.busy": "2021-12-17T08:00:05.668460Z",
          "iopub.status.idle": "2021-12-17T08:00:05.670283Z",
          "shell.execute_reply": "2021-12-17T08:00:05.670708Z",
          "shell.execute_reply.started": "2021-12-17T07:48:09.402544Z"
        },
        "id": "d1c96e52",
        "papermill": {
          "duration": 0.084698,
          "end_time": "2021-12-17T08:00:05.670850",
          "exception": false,
          "start_time": "2021-12-17T08:00:05.586152",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bee6fe51",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:05.828054Z",
          "iopub.status.busy": "2021-12-17T08:00:05.827089Z",
          "iopub.status.idle": "2021-12-17T08:00:06.470574Z",
          "shell.execute_reply": "2021-12-17T08:00:06.470099Z",
          "shell.execute_reply.started": "2021-12-17T07:48:09.409281Z"
        },
        "id": "bee6fe51",
        "papermill": {
          "duration": 0.724654,
          "end_time": "2021-12-17T08:00:06.470737",
          "exception": false,
          "start_time": "2021-12-17T08:00:05.746083",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "daf5e50e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:06.642522Z",
          "iopub.status.busy": "2021-12-17T08:00:06.641682Z",
          "iopub.status.idle": "2021-12-17T08:00:06.654716Z",
          "shell.execute_reply": "2021-12-17T08:00:06.654255Z",
          "shell.execute_reply.started": "2021-12-17T07:48:09.992755Z"
        },
        "id": "daf5e50e",
        "outputId": "0dbe9990-f22c-42e1-837d-0dabe27a0e03",
        "papermill": {
          "duration": 0.101731,
          "end_time": "2021-12-17T08:00:06.654844",
          "exception": false,
          "start_time": "2021-12-17T08:00:06.553113",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fa2f5210-35d9-483d-bd09-c88c409d5954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa2f5210-35d9-483d-bd09-c88c409d5954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa2f5210-35d9-483d-bd09-c88c409d5954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa2f5210-35d9-483d-bd09-c88c409d5954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a363fefb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:06.842456Z",
          "iopub.status.busy": "2021-12-17T08:00:06.841749Z",
          "iopub.status.idle": "2021-12-17T08:00:06.844533Z",
          "shell.execute_reply": "2021-12-17T08:00:06.844958Z",
          "shell.execute_reply.started": "2021-12-17T07:48:10.013579Z"
        },
        "id": "a363fefb",
        "outputId": "8efc9ff7-9cb3-4b58-938a-e22b279b9066",
        "papermill": {
          "duration": 0.114409,
          "end_time": "2021-12-17T08:00:06.845103",
          "exception": false,
          "start_time": "2021-12-17T08:00:06.730694",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f87dfcf",
      "metadata": {
        "id": "1f87dfcf",
        "papermill": {
          "duration": 0.075734,
          "end_time": "2021-12-17T08:00:06.997539",
          "exception": false,
          "start_time": "2021-12-17T08:00:06.921805",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9012b225",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:00:07.180740Z",
          "iopub.status.busy": "2021-12-17T08:00:07.179862Z",
          "iopub.status.idle": "2021-12-17T08:02:47.943731Z",
          "shell.execute_reply": "2021-12-17T08:02:47.943148Z",
          "shell.execute_reply.started": "2021-12-17T07:48:10.051596Z"
        },
        "id": "9012b225",
        "outputId": "eeaa9437-a56b-4ade-8043-d07d82581a36",
        "papermill": {
          "duration": 160.857576,
          "end_time": "2021-12-17T08:02:47.943904",
          "exception": false,
          "start_time": "2021-12-17T08:00:07.086328",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-17 12:09:26--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  32.2MB/s    in 39s     \n",
            "\n",
            "2021-12-17 12:10:06 (31.7 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "99a841eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:09.379435Z",
          "iopub.status.busy": "2021-12-17T08:03:09.374751Z",
          "iopub.status.idle": "2021-12-17T08:03:10.064435Z",
          "shell.execute_reply": "2021-12-17T08:03:10.065225Z",
          "shell.execute_reply.started": "2021-12-17T07:50:27.288296Z"
        },
        "id": "99a841eb",
        "outputId": "a49d5754-02c7-44ef-adef-254784452644",
        "papermill": {
          "duration": 0.942588,
          "end_time": "2021-12-17T08:03:10.065385",
          "exception": false,
          "start_time": "2021-12-17T08:03:09.122797",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec 17 12:09 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8763b456",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:11.373703Z",
          "iopub.status.busy": "2021-12-17T08:03:11.372668Z",
          "iopub.status.idle": "2021-12-17T08:03:11.374724Z",
          "shell.execute_reply": "2021-12-17T08:03:11.375188Z",
          "shell.execute_reply.started": "2021-12-17T07:50:27.958197Z"
        },
        "id": "8763b456",
        "papermill": {
          "duration": 0.945581,
          "end_time": "2021-12-17T08:03:11.375336",
          "exception": false,
          "start_time": "2021-12-17T08:03:10.429755",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "aa66f9da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:12.032539Z",
          "iopub.status.busy": "2021-12-17T08:03:12.031727Z",
          "iopub.status.idle": "2021-12-17T08:03:12.033592Z",
          "shell.execute_reply": "2021-12-17T08:03:12.034188Z",
          "shell.execute_reply.started": "2021-12-17T07:50:32.497153Z"
        },
        "id": "aa66f9da",
        "papermill": {
          "duration": 0.356665,
          "end_time": "2021-12-17T08:03:12.034396",
          "exception": false,
          "start_time": "2021-12-17T08:03:11.677731",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "183e5237",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:12.775901Z",
          "iopub.status.busy": "2021-12-17T08:03:12.775099Z",
          "iopub.status.idle": "2021-12-17T08:03:16.003849Z",
          "shell.execute_reply": "2021-12-17T08:03:16.003268Z",
          "shell.execute_reply.started": "2021-12-17T07:50:37.883280Z"
        },
        "id": "183e5237",
        "outputId": "d904e8e5-f054-443d-f3cc-13468fe99688",
        "papermill": {
          "duration": 3.596744,
          "end_time": "2021-12-17T08:03:16.004011",
          "exception": false,
          "start_time": "2021-12-17T08:03:12.407267",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:02<00:00, 85754.23it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "95b3cd93",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:17.578355Z",
          "iopub.status.busy": "2021-12-17T08:03:17.577698Z",
          "iopub.status.idle": "2021-12-17T08:03:17.700282Z",
          "shell.execute_reply": "2021-12-17T08:03:17.700716Z",
          "shell.execute_reply.started": "2021-12-17T07:50:46.381794Z"
        },
        "id": "95b3cd93",
        "papermill": {
          "duration": 1.435879,
          "end_time": "2021-12-17T08:03:17.700895",
          "exception": false,
          "start_time": "2021-12-17T08:03:16.265016",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "40fc93b2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:18.205055Z",
          "iopub.status.busy": "2021-12-17T08:03:18.203054Z",
          "iopub.status.idle": "2021-12-17T08:03:19.580336Z",
          "shell.execute_reply": "2021-12-17T08:03:19.581473Z",
          "shell.execute_reply.started": "2021-12-17T07:50:48.108260Z"
        },
        "id": "40fc93b2",
        "outputId": "2244e9ee-d78b-421d-9038-5ae8c746f749",
        "papermill": {
          "duration": 1.645158,
          "end_time": "2021-12-17T08:03:19.581725",
          "exception": false,
          "start_time": "2021-12-17T08:03:17.936567",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f3b37ffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "45cbeca6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:20.226409Z",
          "iopub.status.busy": "2021-12-17T08:03:20.225660Z",
          "iopub.status.idle": "2021-12-17T08:03:20.228988Z",
          "shell.execute_reply": "2021-12-17T08:03:20.229394Z",
          "shell.execute_reply.started": "2021-12-17T07:50:49.374155Z"
        },
        "id": "45cbeca6",
        "outputId": "fbd70c90-9782-4de4-ef83-5e4b331f43e4",
        "papermill": {
          "duration": 0.260813,
          "end_time": "2021-12-17T08:03:20.229533",
          "exception": false,
          "start_time": "2021-12-17T08:03:19.968720",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9a7c8cae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:20.711340Z",
          "iopub.status.busy": "2021-12-17T08:03:20.710418Z",
          "iopub.status.idle": "2021-12-17T08:03:20.714221Z",
          "shell.execute_reply": "2021-12-17T08:03:20.714577Z",
          "shell.execute_reply.started": "2021-12-17T07:50:49.548096Z"
        },
        "id": "9a7c8cae",
        "outputId": "72fca562-426e-4870-b479-9ff8763eb387",
        "papermill": {
          "duration": 0.2505,
          "end_time": "2021-12-17T08:03:20.714748",
          "exception": false,
          "start_time": "2021-12-17T08:03:20.464248",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "977be5eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:21.202305Z",
          "iopub.status.busy": "2021-12-17T08:03:21.197165Z",
          "iopub.status.idle": "2021-12-17T08:03:21.215889Z",
          "shell.execute_reply": "2021-12-17T08:03:21.215434Z",
          "shell.execute_reply.started": "2021-12-17T07:50:49.555619Z"
        },
        "id": "977be5eb",
        "outputId": "cfba9ab8-0191-4c61-f608-2a0f9df4d939",
        "papermill": {
          "duration": 0.272711,
          "end_time": "2021-12-17T08:03:21.216021",
          "exception": false,
          "start_time": "2021-12-17T08:03:20.943310",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62fe1085",
      "metadata": {
        "id": "62fe1085",
        "papermill": {
          "duration": 0.254365,
          "end_time": "2021-12-17T08:03:21.708301",
          "exception": false,
          "start_time": "2021-12-17T08:03:21.453936",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e3c5f026",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:22.184866Z",
          "iopub.status.busy": "2021-12-17T08:03:22.184054Z",
          "iopub.status.idle": "2021-12-17T08:03:22.186532Z",
          "shell.execute_reply": "2021-12-17T08:03:22.186129Z",
          "shell.execute_reply.started": "2021-12-17T07:50:50.304311Z"
        },
        "id": "e3c5f026",
        "papermill": {
          "duration": 0.235128,
          "end_time": "2021-12-17T08:03:22.186664",
          "exception": false,
          "start_time": "2021-12-17T08:03:21.951536",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b3799585",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:03:22.662414Z",
          "iopub.status.busy": "2021-12-17T08:03:22.661522Z",
          "iopub.status.idle": "2021-12-17T08:04:38.455698Z",
          "shell.execute_reply": "2021-12-17T08:04:38.455160Z",
          "shell.execute_reply.started": "2021-12-17T07:50:50.310920Z"
        },
        "id": "b3799585",
        "outputId": "879b3dca-38f1-42c6-98bf-38e21f9ef9f6",
        "papermill": {
          "duration": 76.039495,
          "end_time": "2021-12-17T08:04:38.455844",
          "exception": false,
          "start_time": "2021-12-17T08:03:22.416349",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:19<00:00, 25221.97it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "536236b7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:39.284405Z",
          "iopub.status.busy": "2021-12-17T08:04:39.283695Z",
          "iopub.status.idle": "2021-12-17T08:04:39.286695Z",
          "shell.execute_reply": "2021-12-17T08:04:39.287168Z",
          "shell.execute_reply.started": "2021-12-17T07:52:04.880838Z"
        },
        "id": "536236b7",
        "outputId": "6068034d-f556-4217-89fd-b47c23cfdbc4",
        "papermill": {
          "duration": 0.422641,
          "end_time": "2021-12-17T08:04:39.287320",
          "exception": false,
          "start_time": "2021-12-17T08:04:38.864679",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fdcc1ea9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:40.260184Z",
          "iopub.status.busy": "2021-12-17T08:04:40.250066Z",
          "iopub.status.idle": "2021-12-17T08:04:40.310421Z",
          "shell.execute_reply": "2021-12-17T08:04:40.309983Z",
          "shell.execute_reply.started": "2021-12-17T07:52:04.887522Z"
        },
        "id": "fdcc1ea9",
        "outputId": "f83ed495-f9b5-481d-e31a-1a55c88d7d77",
        "papermill": {
          "duration": 0.514768,
          "end_time": "2021-12-17T08:04:40.310560",
          "exception": false,
          "start_time": "2021-12-17T08:04:39.795792",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eeb8966",
      "metadata": {
        "id": "9eeb8966",
        "papermill": {
          "duration": 0.409524,
          "end_time": "2021-12-17T08:04:41.129685",
          "exception": false,
          "start_time": "2021-12-17T08:04:40.720161",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5c9d9dc5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:42.005948Z",
          "iopub.status.busy": "2021-12-17T08:04:42.003271Z",
          "iopub.status.idle": "2021-12-17T08:04:43.462634Z",
          "shell.execute_reply": "2021-12-17T08:04:43.462057Z",
          "shell.execute_reply.started": "2021-12-17T07:52:04.980819Z"
        },
        "id": "5c9d9dc5",
        "papermill": {
          "duration": 1.903971,
          "end_time": "2021-12-17T08:04:43.462787",
          "exception": false,
          "start_time": "2021-12-17T08:04:41.558816",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63390f3",
      "metadata": {
        "id": "c63390f3",
        "papermill": {
          "duration": 0.46236,
          "end_time": "2021-12-17T08:04:44.375259",
          "exception": false,
          "start_time": "2021-12-17T08:04:43.912899",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a1373bda",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:45.206301Z",
          "iopub.status.busy": "2021-12-17T08:04:45.205686Z",
          "iopub.status.idle": "2021-12-17T08:04:45.273182Z",
          "shell.execute_reply": "2021-12-17T08:04:45.272717Z",
          "shell.execute_reply.started": "2021-12-17T07:52:06.206857Z"
        },
        "id": "a1373bda",
        "papermill": {
          "duration": 0.490174,
          "end_time": "2021-12-17T08:04:45.273311",
          "exception": false,
          "start_time": "2021-12-17T08:04:44.783137",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f2e537dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:46.098808Z",
          "iopub.status.busy": "2021-12-17T08:04:46.098116Z",
          "iopub.status.idle": "2021-12-17T08:04:46.124702Z",
          "shell.execute_reply": "2021-12-17T08:04:46.125133Z",
          "shell.execute_reply.started": "2021-12-17T07:52:06.281430Z"
        },
        "id": "f2e537dc",
        "papermill": {
          "duration": 0.444393,
          "end_time": "2021-12-17T08:04:46.125297",
          "exception": false,
          "start_time": "2021-12-17T08:04:45.680904",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fa9c6eaf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:46.962273Z",
          "iopub.status.busy": "2021-12-17T08:04:46.961709Z",
          "iopub.status.idle": "2021-12-17T08:04:51.292576Z",
          "shell.execute_reply": "2021-12-17T08:04:51.293768Z",
          "shell.execute_reply.started": "2021-12-17T07:52:06.317473Z"
        },
        "id": "fa9c6eaf",
        "outputId": "06ebe5e5-7661-4763-b0ba-9f92d3233bcd",
        "papermill": {
          "duration": 4.74802,
          "end_time": "2021-12-17T08:04:51.294024",
          "exception": false,
          "start_time": "2021-12-17T08:04:46.546004",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 836 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a25ef4f2",
      "metadata": {
        "id": "a25ef4f2",
        "papermill": {
          "duration": 0.455857,
          "end_time": "2021-12-17T08:04:52.277069",
          "exception": false,
          "start_time": "2021-12-17T08:04:51.821212",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "26e7ddd5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:53.261442Z",
          "iopub.status.busy": "2021-12-17T08:04:53.260794Z",
          "iopub.status.idle": "2021-12-17T08:04:53.266645Z",
          "shell.execute_reply": "2021-12-17T08:04:53.266160Z",
          "shell.execute_reply.started": "2021-12-17T07:52:11.089091Z"
        },
        "id": "26e7ddd5",
        "outputId": "3e3d0a06-b8f6-409d-fb8f-f6ca2c65a166",
        "papermill": {
          "duration": 0.529787,
          "end_time": "2021-12-17T08:04:53.266778",
          "exception": false,
          "start_time": "2021-12-17T08:04:52.736991",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2b36a0cf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:54.158233Z",
          "iopub.status.busy": "2021-12-17T08:04:54.157703Z",
          "iopub.status.idle": "2021-12-17T08:04:54.161422Z",
          "shell.execute_reply": "2021-12-17T08:04:54.160999Z",
          "shell.execute_reply.started": "2021-12-17T07:52:11.142419Z"
        },
        "id": "2b36a0cf",
        "papermill": {
          "duration": 0.43857,
          "end_time": "2021-12-17T08:04:54.161540",
          "exception": false,
          "start_time": "2021-12-17T08:04:53.722970",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c7d132df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:55.030697Z",
          "iopub.status.busy": "2021-12-17T08:04:55.030150Z",
          "iopub.status.idle": "2021-12-17T08:04:57.351789Z",
          "shell.execute_reply": "2021-12-17T08:04:57.352394Z",
          "shell.execute_reply.started": "2021-12-17T07:52:11.149373Z"
        },
        "id": "c7d132df",
        "papermill": {
          "duration": 2.741181,
          "end_time": "2021-12-17T08:04:57.352603",
          "exception": false,
          "start_time": "2021-12-17T08:04:54.611422",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a51babe1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:58.251331Z",
          "iopub.status.busy": "2021-12-17T08:04:58.250530Z",
          "iopub.status.idle": "2021-12-17T08:04:59.050768Z",
          "shell.execute_reply": "2021-12-17T08:04:59.050246Z",
          "shell.execute_reply.started": "2021-12-17T07:52:13.447259Z"
        },
        "id": "a51babe1",
        "papermill": {
          "duration": 1.284162,
          "end_time": "2021-12-17T08:04:59.050926",
          "exception": false,
          "start_time": "2021-12-17T08:04:57.766764",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "15c94690",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:04:59.967981Z",
          "iopub.status.busy": "2021-12-17T08:04:59.967405Z",
          "iopub.status.idle": "2021-12-17T08:05:08.123538Z",
          "shell.execute_reply": "2021-12-17T08:05:08.122822Z",
          "shell.execute_reply.started": "2021-12-17T07:52:14.160324Z"
        },
        "id": "15c94690",
        "outputId": "f0fb46a4-453b-4083-970d-bd30ad1012cb",
        "papermill": {
          "duration": 8.612816,
          "end_time": "2021-12-17T08:05:08.123739",
          "exception": false,
          "start_time": "2021-12-17T08:04:59.510923",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 30.8 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d504c5e0",
      "metadata": {
        "id": "d504c5e0",
        "papermill": {
          "duration": 0.417851,
          "end_time": "2021-12-17T08:05:08.985279",
          "exception": false,
          "start_time": "2021-12-17T08:05:08.567428",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "40d82100",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:10.069196Z",
          "iopub.status.busy": "2021-12-17T08:05:10.068229Z",
          "iopub.status.idle": "2021-12-17T08:05:10.070279Z",
          "shell.execute_reply": "2021-12-17T08:05:10.070782Z",
          "shell.execute_reply.started": "2021-12-17T07:52:22.132652Z"
        },
        "id": "40d82100",
        "papermill": {
          "duration": 0.533622,
          "end_time": "2021-12-17T08:05:10.070941",
          "exception": false,
          "start_time": "2021-12-17T08:05:09.537319",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb4e69b",
      "metadata": {
        "id": "8eb4e69b",
        "papermill": {
          "duration": 0.415154,
          "end_time": "2021-12-17T08:05:10.916314",
          "exception": false,
          "start_time": "2021-12-17T08:05:10.501160",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0e0377",
      "metadata": {
        "id": "1c0e0377",
        "papermill": {
          "duration": 0.422972,
          "end_time": "2021-12-17T08:05:11.770547",
          "exception": false,
          "start_time": "2021-12-17T08:05:11.347575",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632b809a",
      "metadata": {
        "id": "632b809a",
        "papermill": {
          "duration": 0.410196,
          "end_time": "2021-12-17T08:05:12.590008",
          "exception": false,
          "start_time": "2021-12-17T08:05:12.179812",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "6eb7e40a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:13.418349Z",
          "iopub.status.busy": "2021-12-17T08:05:13.417542Z",
          "iopub.status.idle": "2021-12-17T08:05:13.940885Z",
          "shell.execute_reply": "2021-12-17T08:05:13.941297Z",
          "shell.execute_reply.started": "2021-12-17T07:52:22.139193Z"
        },
        "id": "6eb7e40a",
        "papermill": {
          "duration": 0.938785,
          "end_time": "2021-12-17T08:05:13.941470",
          "exception": false,
          "start_time": "2021-12-17T08:05:13.002685",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4a035a66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:14.784052Z",
          "iopub.status.busy": "2021-12-17T08:05:14.783171Z",
          "iopub.status.idle": "2021-12-17T08:05:14.785870Z",
          "shell.execute_reply": "2021-12-17T08:05:14.786266Z",
          "shell.execute_reply.started": "2021-12-17T07:52:22.654913Z"
        },
        "id": "4a035a66",
        "outputId": "8b535c60-7bf9-4338-e788-302bab7791b1",
        "papermill": {
          "duration": 0.425205,
          "end_time": "2021-12-17T08:05:14.786403",
          "exception": false,
          "start_time": "2021-12-17T08:05:14.361198",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0e8cbb55",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:15.661392Z",
          "iopub.status.busy": "2021-12-17T08:05:15.660590Z",
          "iopub.status.idle": "2021-12-17T08:05:16.233171Z",
          "shell.execute_reply": "2021-12-17T08:05:16.232531Z",
          "shell.execute_reply.started": "2021-12-17T07:52:22.664710Z"
        },
        "id": "0e8cbb55",
        "papermill": {
          "duration": 1.025239,
          "end_time": "2021-12-17T08:05:16.233306",
          "exception": false,
          "start_time": "2021-12-17T08:05:15.208067",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "7821f1bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:17.058065Z",
          "iopub.status.busy": "2021-12-17T08:05:17.057307Z",
          "iopub.status.idle": "2021-12-17T08:05:17.060154Z",
          "shell.execute_reply": "2021-12-17T08:05:17.060557Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.248089Z"
        },
        "id": "7821f1bf",
        "outputId": "41b18c7a-77ac-4797-b559-1a2f9c6df9ec",
        "papermill": {
          "duration": 0.417684,
          "end_time": "2021-12-17T08:05:17.060709",
          "exception": false,
          "start_time": "2021-12-17T08:05:16.643025",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9b6bceeb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:17.887038Z",
          "iopub.status.busy": "2021-12-17T08:05:17.886190Z",
          "iopub.status.idle": "2021-12-17T08:05:17.889183Z",
          "shell.execute_reply": "2021-12-17T08:05:17.889582Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.255862Z"
        },
        "id": "9b6bceeb",
        "outputId": "5e480ec7-b9e0-4bea-be5e-71ead4b71eae",
        "papermill": {
          "duration": 0.42094,
          "end_time": "2021-12-17T08:05:17.889739",
          "exception": false,
          "start_time": "2021-12-17T08:05:17.468799",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc2d37b7",
      "metadata": {
        "id": "bc2d37b7",
        "papermill": {
          "duration": 0.436409,
          "end_time": "2021-12-17T08:05:18.798526",
          "exception": false,
          "start_time": "2021-12-17T08:05:18.362117",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8ef7d330",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:19.625999Z",
          "iopub.status.busy": "2021-12-17T08:05:19.622469Z",
          "iopub.status.idle": "2021-12-17T08:05:19.630785Z",
          "shell.execute_reply": "2021-12-17T08:05:19.630311Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.269188Z"
        },
        "id": "8ef7d330",
        "outputId": "ef5c13b2-ff1c-4ede-ed37-1ed0be6036f5",
        "papermill": {
          "duration": 0.421316,
          "end_time": "2021-12-17T08:05:19.630906",
          "exception": false,
          "start_time": "2021-12-17T08:05:19.209590",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5b0cb89",
      "metadata": {
        "id": "d5b0cb89",
        "papermill": {
          "duration": 0.651533,
          "end_time": "2021-12-17T08:05:20.692978",
          "exception": false,
          "start_time": "2021-12-17T08:05:20.041445",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "59d0e790",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:21.587694Z",
          "iopub.status.busy": "2021-12-17T08:05:21.586898Z",
          "iopub.status.idle": "2021-12-17T08:05:21.600122Z",
          "shell.execute_reply": "2021-12-17T08:05:21.599651Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.281541Z"
        },
        "id": "59d0e790",
        "papermill": {
          "duration": 0.430998,
          "end_time": "2021-12-17T08:05:21.600237",
          "exception": false,
          "start_time": "2021-12-17T08:05:21.169239",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b6ec930c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:22.460890Z",
          "iopub.status.busy": "2021-12-17T08:05:22.459248Z",
          "iopub.status.idle": "2021-12-17T08:05:22.461451Z",
          "shell.execute_reply": "2021-12-17T08:05:22.461874Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.299947Z"
        },
        "id": "b6ec930c",
        "papermill": {
          "duration": 0.424113,
          "end_time": "2021-12-17T08:05:22.462016",
          "exception": false,
          "start_time": "2021-12-17T08:05:22.037903",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "76a201b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:23.472760Z",
          "iopub.status.busy": "2021-12-17T08:05:23.472026Z",
          "iopub.status.idle": "2021-12-17T08:05:23.475214Z",
          "shell.execute_reply": "2021-12-17T08:05:23.475879Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.305494Z"
        },
        "id": "76a201b9",
        "outputId": "7e697efc-e982-4bf1-b4cc-a4152dfbc408",
        "papermill": {
          "duration": 0.602774,
          "end_time": "2021-12-17T08:05:23.476079",
          "exception": false,
          "start_time": "2021-12-17T08:05:22.873305",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4085edea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:24.678818Z",
          "iopub.status.busy": "2021-12-17T08:05:24.677167Z",
          "iopub.status.idle": "2021-12-17T08:05:24.946435Z",
          "shell.execute_reply": "2021-12-17T08:05:24.945793Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.315516Z"
        },
        "id": "4085edea",
        "outputId": "16c14108-86c2-4a90-efc8-5dba8b398a3f",
        "papermill": {
          "duration": 0.71768,
          "end_time": "2021-12-17T08:05:24.946570",
          "exception": false,
          "start_time": "2021-12-17T08:05:24.228890",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6d794117",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:25.813402Z",
          "iopub.status.busy": "2021-12-17T08:05:25.812741Z",
          "iopub.status.idle": "2021-12-17T08:05:25.815504Z",
          "shell.execute_reply": "2021-12-17T08:05:25.815926Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.616877Z"
        },
        "id": "6d794117",
        "outputId": "bb4bb469-9068-41f9-b1a8-26dc5bbc7edc",
        "papermill": {
          "duration": 0.440379,
          "end_time": "2021-12-17T08:05:25.816067",
          "exception": false,
          "start_time": "2021-12-17T08:05:25.375688",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5162850e",
      "metadata": {
        "id": "5162850e",
        "papermill": {
          "duration": 0.443007,
          "end_time": "2021-12-17T08:05:26.671967",
          "exception": false,
          "start_time": "2021-12-17T08:05:26.228960",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c9a92837",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:27.522741Z",
          "iopub.status.busy": "2021-12-17T08:05:27.521839Z",
          "iopub.status.idle": "2021-12-17T08:05:27.523492Z",
          "shell.execute_reply": "2021-12-17T08:05:27.524013Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.627091Z"
        },
        "id": "c9a92837",
        "papermill": {
          "duration": 0.437433,
          "end_time": "2021-12-17T08:05:27.524151",
          "exception": false,
          "start_time": "2021-12-17T08:05:27.086718",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "53c24ed4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:28.436160Z",
          "iopub.status.busy": "2021-12-17T08:05:28.435441Z",
          "iopub.status.idle": "2021-12-17T08:05:28.438321Z",
          "shell.execute_reply": "2021-12-17T08:05:28.438752Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.634970Z"
        },
        "id": "53c24ed4",
        "outputId": "5283ab12-f832-4e20-8a86-654719c66c5e",
        "papermill": {
          "duration": 0.47342,
          "end_time": "2021-12-17T08:05:28.438907",
          "exception": false,
          "start_time": "2021-12-17T08:05:27.965487",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "6996b3b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:29.336381Z",
          "iopub.status.busy": "2021-12-17T08:05:29.335689Z",
          "iopub.status.idle": "2021-12-17T08:05:29.338473Z",
          "shell.execute_reply": "2021-12-17T08:05:29.338887Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.646859Z"
        },
        "id": "6996b3b3",
        "outputId": "4aae5d30-51fd-4660-b8e6-7e2e36de726b",
        "papermill": {
          "duration": 0.468201,
          "end_time": "2021-12-17T08:05:29.339027",
          "exception": false,
          "start_time": "2021-12-17T08:05:28.870826",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5d11a2af-ce41-40e1-9abb-b31c194f7ea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d11a2af-ce41-40e1-9abb-b31c194f7ea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d11a2af-ce41-40e1-9abb-b31c194f7ea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d11a2af-ce41-40e1-9abb-b31c194f7ea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8537e9",
      "metadata": {
        "id": "3a8537e9",
        "papermill": {
          "duration": 0.4136,
          "end_time": "2021-12-17T08:05:30.164607",
          "exception": false,
          "start_time": "2021-12-17T08:05:29.751007",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "b1a7d27d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:31.028812Z",
          "iopub.status.busy": "2021-12-17T08:05:31.028034Z",
          "iopub.status.idle": "2021-12-17T08:05:31.035562Z",
          "shell.execute_reply": "2021-12-17T08:05:31.035148Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.658943Z"
        },
        "id": "b1a7d27d",
        "papermill": {
          "duration": 0.440125,
          "end_time": "2021-12-17T08:05:31.035708",
          "exception": false,
          "start_time": "2021-12-17T08:05:30.595583",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ec7d9295",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:32.191711Z",
          "iopub.status.busy": "2021-12-17T08:05:32.190087Z",
          "iopub.status.idle": "2021-12-17T08:05:32.194220Z",
          "shell.execute_reply": "2021-12-17T08:05:32.193686Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.686445Z"
        },
        "id": "ec7d9295",
        "outputId": "22264bf8-7d3f-4d3d-bc2f-94dbbf3fb1e6",
        "papermill": {
          "duration": 0.547179,
          "end_time": "2021-12-17T08:05:32.194348",
          "exception": false,
          "start_time": "2021-12-17T08:05:31.647169",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'food': 4, 'law': 1, 'love': 2, 'relax': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "473d9fa0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:33.066223Z",
          "iopub.status.busy": "2021-12-17T08:05:33.065341Z",
          "iopub.status.idle": "2021-12-17T08:05:33.072110Z",
          "shell.execute_reply": "2021-12-17T08:05:33.072490Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.695545Z"
        },
        "id": "473d9fa0",
        "papermill": {
          "duration": 0.440645,
          "end_time": "2021-12-17T08:05:33.072659",
          "exception": false,
          "start_time": "2021-12-17T08:05:32.632014",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7184959d",
      "metadata": {
        "id": "7184959d",
        "papermill": {
          "duration": 0.413056,
          "end_time": "2021-12-17T08:05:33.898115",
          "exception": false,
          "start_time": "2021-12-17T08:05:33.485059",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8af8b5e4",
      "metadata": {
        "id": "8af8b5e4",
        "papermill": {
          "duration": 0.435528,
          "end_time": "2021-12-17T08:05:34.758983",
          "exception": false,
          "start_time": "2021-12-17T08:05:34.323455",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f5d5ce38",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:35.600583Z",
          "iopub.status.busy": "2021-12-17T08:05:35.599664Z",
          "iopub.status.idle": "2021-12-17T08:05:35.602216Z",
          "shell.execute_reply": "2021-12-17T08:05:35.601789Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.720186Z"
        },
        "id": "f5d5ce38",
        "papermill": {
          "duration": 0.427926,
          "end_time": "2021-12-17T08:05:35.602325",
          "exception": false,
          "start_time": "2021-12-17T08:05:35.174399",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "703be945",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:36.461747Z",
          "iopub.status.busy": "2021-12-17T08:05:36.460738Z",
          "iopub.status.idle": "2021-12-17T08:05:36.462525Z",
          "shell.execute_reply": "2021-12-17T08:05:36.462969Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.734664Z"
        },
        "id": "703be945",
        "papermill": {
          "duration": 0.429944,
          "end_time": "2021-12-17T08:05:36.463107",
          "exception": false,
          "start_time": "2021-12-17T08:05:36.033163",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "7db8be9e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:37.303117Z",
          "iopub.status.busy": "2021-12-17T08:05:37.302501Z",
          "iopub.status.idle": "2021-12-17T08:05:40.843763Z",
          "shell.execute_reply": "2021-12-17T08:05:40.844239Z",
          "shell.execute_reply.started": "2021-12-17T07:52:23.746820Z"
        },
        "id": "7db8be9e",
        "outputId": "4b2ef5a6-ed66-4317-d893-7606d9174952",
        "papermill": {
          "duration": 3.96863,
          "end_time": "2021-12-17T08:05:40.844383",
          "exception": false,
          "start_time": "2021-12-17T08:05:36.875753",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:03<00:00, 65729.83it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 69654.12it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "8c298bc7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:41.730825Z",
          "iopub.status.busy": "2021-12-17T08:05:41.730081Z",
          "iopub.status.idle": "2021-12-17T08:05:41.736808Z",
          "shell.execute_reply": "2021-12-17T08:05:41.737189Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.093060Z"
        },
        "id": "8c298bc7",
        "papermill": {
          "duration": 0.466981,
          "end_time": "2021-12-17T08:05:41.737337",
          "exception": false,
          "start_time": "2021-12-17T08:05:41.270356",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ce6acf21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:42.883458Z",
          "iopub.status.busy": "2021-12-17T08:05:42.882597Z",
          "iopub.status.idle": "2021-12-17T08:05:42.887324Z",
          "shell.execute_reply": "2021-12-17T08:05:42.886899Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.105293Z"
        },
        "id": "ce6acf21",
        "outputId": "b672b3f5-7c2b-41b3-8e1a-1594ab586eaa",
        "papermill": {
          "duration": 0.727386,
          "end_time": "2021-12-17T08:05:42.887431",
          "exception": false,
          "start_time": "2021-12-17T08:05:42.160045",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   26,    75, 46244,  ...,     0,     0,     0],\n",
              "        [58018,  2372, 12009,  ...,     0,     0,     0],\n",
              "        [13208,    38,   112,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [35178,  4356,     9,  ...,     0,     0,     0],\n",
              "        [21434, 43946,     4,  ...,     0,     0,     0],\n",
              "        [27842, 33086,  3717,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "023bf397",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:43.796286Z",
          "iopub.status.busy": "2021-12-17T08:05:43.795273Z",
          "iopub.status.idle": "2021-12-17T08:05:43.800229Z",
          "shell.execute_reply": "2021-12-17T08:05:43.799751Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.114659Z"
        },
        "id": "023bf397",
        "outputId": "515f55d1-2c89-4bbe-cfae-80670147683b",
        "papermill": {
          "duration": 0.48785,
          "end_time": "2021-12-17T08:05:43.800360",
          "exception": false,
          "start_time": "2021-12-17T08:05:43.312510",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 3, 1, 1, 0, 3, 3, 2, 4, 0, 0, 1, 1, 0, 3, 2, 1, 1, 3, 2, 4, 3, 0, 3,\n",
              "        0, 2, 4, 1, 1, 0, 0, 1, 1, 4, 0, 1, 4, 1, 1, 3, 1, 1, 3, 4, 4, 3, 2, 3,\n",
              "        2, 3, 0, 4, 4, 0, 3, 0, 3, 0, 2, 1, 1, 1, 1, 3])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4656c1",
      "metadata": {
        "id": "ef4656c1",
        "papermill": {
          "duration": 0.452524,
          "end_time": "2021-12-17T08:05:44.693391",
          "exception": false,
          "start_time": "2021-12-17T08:05:44.240867",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10182a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:45.581376Z",
          "iopub.status.busy": "2021-12-17T08:05:45.580361Z",
          "iopub.status.idle": "2021-12-17T08:05:45.582438Z",
          "shell.execute_reply": "2021-12-17T08:05:45.582960Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.125034Z"
        },
        "id": "b10182a3",
        "papermill": {
          "duration": 0.461651,
          "end_time": "2021-12-17T08:05:45.583113",
          "exception": false,
          "start_time": "2021-12-17T08:05:45.121462",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "      def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "\n",
        "            super().__init__()\n",
        "\n",
        "            self.n = n\n",
        "\n",
        "            self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "            self.LSTM = torch.nn.LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "            # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "\n",
        "            self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "            self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "            self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "            self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "            self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,)) # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "            self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "            self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "\n",
        "            self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          x_emb = self.emb_layer(x) #примените эмбеддинги \n",
        "          # транспонируйте тензор для лстм как было описано выше\n",
        "          x_lstm, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "\n",
        "          x_q = self.q_proj(x_lstm) # применим линейные преобразования для селф-эттеншена\n",
        "          x_k = self.k_proj(x_lstm)\n",
        "          x_v = self.v_proj(x_lstm)\n",
        "\n",
        "          att_scores = torch.bmm(x_q, x_k.transpose(2, 1))\n",
        "          # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "          # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "          att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "          attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "          x_att = attention_vectors.transpose(2, 1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "          x_cnn3 = self.cnn_3gr(x_att)\n",
        "          x_cnn4 = self.cnn_4gr(x_att)\n",
        "          x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "          frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "          sc, _ = x_cnn4.max(dim= -1,)\n",
        "          thr, _ = x_cnn5.max(dim= -1,)\n",
        "\n",
        "          x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "\n",
        "          x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "          x = self.relu(x)    \n",
        "          x = self.linear_2(x)\n",
        "\n",
        "          return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5f6314",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:46.440792Z",
          "iopub.status.busy": "2021-12-17T08:05:46.439880Z",
          "iopub.status.idle": "2021-12-17T08:05:46.566166Z",
          "shell.execute_reply": "2021-12-17T08:05:46.566566Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.144219Z"
        },
        "id": "ac5f6314",
        "papermill": {
          "duration": 0.554727,
          "end_time": "2021-12-17T08:05:46.566757",
          "exception": false,
          "start_time": "2021-12-17T08:05:46.012030",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55c72eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:47.446143Z",
          "iopub.status.busy": "2021-12-17T08:05:47.445521Z",
          "iopub.status.idle": "2021-12-17T08:05:47.448156Z",
          "shell.execute_reply": "2021-12-17T08:05:47.448563Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.285672Z"
        },
        "id": "b55c72eb",
        "outputId": "0fb5010d-5c1e-43fa-e8ec-fbff1ebffc7a",
        "papermill": {
          "duration": 0.450106,
          "end_time": "2021-12-17T08:05:47.448711",
          "exception": false,
          "start_time": "2021-12-17T08:05:46.998605",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ec4648",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:48.333739Z",
          "iopub.status.busy": "2021-12-17T08:05:48.332835Z",
          "iopub.status.idle": "2021-12-17T08:05:48.543671Z",
          "shell.execute_reply": "2021-12-17T08:05:48.543118Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.293181Z"
        },
        "id": "e3ec4648",
        "papermill": {
          "duration": 0.672794,
          "end_time": "2021-12-17T08:05:48.543824",
          "exception": false,
          "start_time": "2021-12-17T08:05:47.871030",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ef3617",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:49.414390Z",
          "iopub.status.busy": "2021-12-17T08:05:49.413590Z",
          "iopub.status.idle": "2021-12-17T08:05:49.416224Z",
          "shell.execute_reply": "2021-12-17T08:05:49.416637Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.490892Z"
        },
        "id": "66ef3617",
        "outputId": "49117ad1-e33a-4140-b756-61c7f76857ee",
        "papermill": {
          "duration": 0.432634,
          "end_time": "2021-12-17T08:05:49.416776",
          "exception": false,
          "start_time": "2021-12-17T08:05:48.984142",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97a0657",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:50.315576Z",
          "iopub.status.busy": "2021-12-17T08:05:50.314620Z",
          "iopub.status.idle": "2021-12-17T08:05:50.316359Z",
          "shell.execute_reply": "2021-12-17T08:05:50.316920Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.498359Z"
        },
        "id": "b97a0657",
        "papermill": {
          "duration": 0.471494,
          "end_time": "2021-12-17T08:05:50.317100",
          "exception": false,
          "start_time": "2021-12-17T08:05:49.845606",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed973107",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:51.196634Z",
          "iopub.status.busy": "2021-12-17T08:05:51.195345Z",
          "iopub.status.idle": "2021-12-17T08:05:51.241645Z",
          "shell.execute_reply": "2021-12-17T08:05:51.241140Z",
          "shell.execute_reply.started": "2021-12-17T07:52:27.507380Z"
        },
        "id": "ed973107",
        "papermill": {
          "duration": 0.474564,
          "end_time": "2021-12-17T08:05:51.241775",
          "exception": false,
          "start_time": "2021-12-17T08:05:50.767211",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c37b34c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:05:52.120509Z",
          "iopub.status.busy": "2021-12-17T08:05:52.119582Z",
          "iopub.status.idle": "2021-12-17T08:12:47.869588Z",
          "shell.execute_reply": "2021-12-17T08:12:47.870246Z"
        },
        "id": "3c37b34c",
        "outputId": "f031a6f4-ecc8-48e7-908f-360e966b7dde",
        "papermill": {
          "duration": 416.190638,
          "end_time": "2021-12-17T08:12:47.870484",
          "exception": false,
          "start_time": "2021-12-17T08:05:51.679846",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:25<00:00, 2511.60it/s, train_loss=0.484]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.549, test - 0.469\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:19<00:00, 2692.65it/s, train_loss=0.451]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.456, test - 0.448\n",
            "F1 test - 0.839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:19<00:00, 2678.73it/s, train_loss=0.427]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.429, test - 0.439\n",
            "F1 test - 0.843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:19<00:00, 2677.05it/s, train_loss=0.405]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.406, test - 0.437\n",
            "F1 test - 0.845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [01:20<00:00, 2670.55it/s, train_loss=0.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.383, test - 0.448\n",
            "F1 test - 0.841\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6625b8f9",
      "metadata": {
        "id": "6625b8f9",
        "papermill": {
          "duration": 5.939767,
          "end_time": "2021-12-17T08:12:59.849056",
          "exception": false,
          "start_time": "2021-12-17T08:12:53.909289",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7456c2b",
      "metadata": {
        "id": "d7456c2b",
        "papermill": {
          "duration": 6.305118,
          "end_time": "2021-12-17T08:13:12.160575",
          "exception": false,
          "start_time": "2021-12-17T08:13:05.855457",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов. ✅\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a949bf3",
      "metadata": {
        "id": "3a949bf3",
        "papermill": {
          "duration": 5.748145,
          "end_time": "2021-12-17T08:13:24.099845",
          "exception": false,
          "start_time": "2021-12-17T08:13:18.351700",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Какие эксперименты я ставила:\n",
        "\n",
        "1. Weight decay в Адаме – не улучшило\n",
        "2. Больше линейных слоев и дропаута – вообще перестало нормально учиться\n",
        "3. Стала менять функцию активации на что-то более фэнси: пробовала LeakyReLU, SiLU, остановилась на Parametric ReLU, она и решила задачку с улучшением качества\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "cf089b37",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:13:36.278825Z",
          "iopub.status.busy": "2021-12-17T08:13:36.277827Z",
          "iopub.status.idle": "2021-12-17T08:13:36.279595Z",
          "shell.execute_reply": "2021-12-17T08:13:36.280030Z"
        },
        "id": "cf089b37",
        "papermill": {
          "duration": 6.086344,
          "end_time": "2021-12-17T08:13:36.280170",
          "exception": false,
          "start_time": "2021-12-17T08:13:30.193826",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class model_upd(torch.nn.Module):\n",
        "      def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "\n",
        "            super().__init__()\n",
        "\n",
        "            self.n = n\n",
        "\n",
        "            self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "            self.LSTM = torch.nn.LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "            # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "\n",
        "            self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "            self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "            self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "            self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "            self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,)) # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "            self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "            self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "\n",
        "            self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n",
        "            self.linear_added = torch.nn.Linear(in_features=256, out_features=256, bias=True) \n",
        "            self.relu = torch.nn.PReLU()\n",
        "            self.dropout = torch.nn.Dropout(p=0.5)\n",
        "            self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          x_emb = self.emb_layer(x) #примените эмбеддинги \n",
        "          # транспонируйте тензор для лстм как было описано выше\n",
        "          x_lstm, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "\n",
        "          x_q = self.q_proj(x_lstm) # применим линейные преобразования для селф-эттеншена\n",
        "          x_k = self.k_proj(x_lstm)\n",
        "          x_v = self.v_proj(x_lstm)\n",
        "\n",
        "          att_scores = torch.bmm(x_q, x_k.transpose(2, 1))\n",
        "          # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "          # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "          att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "          attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "          x_att = attention_vectors.transpose(2, 1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "          x_cnn3 = self.cnn_3gr(x_att)\n",
        "          x_cnn4 = self.cnn_4gr(x_att)\n",
        "          x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "          frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "          sc, _ = x_cnn4.max(dim= -1,)\n",
        "          thr, _ = x_cnn5.max(dim= -1,)\n",
        "\n",
        "          x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "\n",
        "          x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "          x = self.dropout(self.relu(x))      \n",
        "          x = self.linear_2(x)\n",
        "\n",
        "          return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d1295b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:13:48.609378Z",
          "iopub.status.busy": "2021-12-17T08:13:48.608519Z",
          "iopub.status.idle": "2021-12-17T08:13:48.610384Z",
          "shell.execute_reply": "2021-12-17T08:13:48.610783Z"
        },
        "id": "76d1295b",
        "papermill": {
          "duration": 6.09179,
          "end_time": "2021-12-17T08:13:48.610932",
          "exception": false,
          "start_time": "2021-12-17T08:13:42.519142",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd821be0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:14:00.598902Z",
          "iopub.status.busy": "2021-12-17T08:14:00.598104Z",
          "iopub.status.idle": "2021-12-17T08:14:00.742689Z",
          "shell.execute_reply": "2021-12-17T08:14:00.742152Z"
        },
        "id": "dd821be0",
        "papermill": {
          "duration": 6.192337,
          "end_time": "2021-12-17T08:14:00.742836",
          "exception": false,
          "start_time": "2021-12-17T08:13:54.550499",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_upd(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7133d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:14:12.814818Z",
          "iopub.status.busy": "2021-12-17T08:14:12.813843Z",
          "iopub.status.idle": "2021-12-17T08:14:13.063314Z",
          "shell.execute_reply": "2021-12-17T08:14:13.063769Z"
        },
        "id": "2b7133d8",
        "papermill": {
          "duration": 6.675586,
          "end_time": "2021-12-17T08:14:13.063934",
          "exception": false,
          "start_time": "2021-12-17T08:14:06.388348",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "model = model_upd(vectors, n_classes)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters()) #, weight_decay=0.0001)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00dad1be",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:14:24.679807Z",
          "iopub.status.busy": "2021-12-17T08:14:24.678937Z",
          "iopub.status.idle": "2021-12-17T08:21:11.859566Z",
          "shell.execute_reply": "2021-12-17T08:21:11.860413Z"
        },
        "id": "00dad1be",
        "outputId": "b9df94d7-c832-4f0a-cbc2-f902d42e0550",
        "papermill": {
          "duration": 413.160986,
          "end_time": "2021-12-17T08:21:11.860707",
          "exception": false,
          "start_time": "2021-12-17T08:14:18.699721",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:19<00:00, 2699.00it/s, train_loss=0.492]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.559, test - 0.470\n",
            "F1 test - 0.831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:19<00:00, 2708.41it/s, train_loss=0.459]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.464, test - 0.450\n",
            "F1 test - 0.838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:19<00:00, 2683.70it/s, train_loss=0.438]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.438, test - 0.442\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:18<00:00, 2718.29it/s, train_loss=0.413]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.416, test - 0.437\n",
            "F1 test - 0.843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [01:19<00:00, 2692.35it/s, train_loss=0.392]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.395, test - 0.449\n",
            "F1 test - 0.842\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "d8d5d29e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:21:35.186918Z",
          "iopub.status.busy": "2021-12-17T08:21:35.186028Z",
          "iopub.status.idle": "2021-12-17T08:21:35.188181Z",
          "shell.execute_reply": "2021-12-17T08:21:35.187668Z"
        },
        "id": "d8d5d29e",
        "papermill": {
          "duration": 11.456077,
          "end_time": "2021-12-17T08:21:35.188297",
          "exception": false,
          "start_time": "2021-12-17T08:21:23.732220",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ExponentialLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "b4736fc4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:21:58.452502Z",
          "iopub.status.busy": "2021-12-17T08:21:58.451522Z",
          "iopub.status.idle": "2021-12-17T08:21:58.613056Z",
          "shell.execute_reply": "2021-12-17T08:21:58.613495Z"
        },
        "id": "b4736fc4",
        "papermill": {
          "duration": 12.197761,
          "end_time": "2021-12-17T08:21:58.613674",
          "exception": false,
          "start_time": "2021-12-17T08:21:46.415913",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_upd(vectors, n_classes)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters()) #, weight_decay=0.0001)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.7)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "69a68430",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:22:21.324103Z",
          "iopub.status.busy": "2021-12-17T08:22:21.323101Z",
          "iopub.status.idle": "2021-12-17T08:29:26.088987Z",
          "shell.execute_reply": "2021-12-17T08:29:26.089702Z"
        },
        "id": "69a68430",
        "papermill": {
          "duration": 435.996996,
          "end_time": "2021-12-17T08:29:26.089918",
          "exception": false,
          "start_time": "2021-12-17T08:22:10.092922",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d78181-723e-43bd-e60d-bf13e22201e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:21<00:00, 1059.55it/s, train_loss=0.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.562, test - 0.485\n",
            "F1 test - 0.821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:21<00:00, 1063.02it/s, train_loss=0.451]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.455, test - 0.465\n",
            "F1 test - 0.829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:21<00:00, 1061.84it/s, train_loss=0.423]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.427, test - 0.448\n",
            "F1 test - 0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:21<00:00, 1060.37it/s, train_loss=0.401]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.407, test - 0.442\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [03:21<00:00, 1062.41it/s, train_loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.389, test - 0.439\n",
            "F1 test - 0.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 214001/214001 [03:21<00:00, 1063.41it/s, train_loss=0.365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.375, test - 0.440\n",
            "F1 test - 0.845\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "\n",
        "    scheduler.step()    \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0212426",
      "metadata": {
        "id": "a0212426",
        "papermill": {
          "duration": 16.779376,
          "end_time": "2021-12-17T08:30:00.022478",
          "exception": false,
          "start_time": "2021-12-17T08:29:43.243102",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246f94a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:30:33.874267Z",
          "iopub.status.busy": "2021-12-17T08:30:33.873346Z",
          "iopub.status.idle": "2021-12-17T08:30:42.152441Z",
          "shell.execute_reply": "2021-12-17T08:30:42.151911Z"
        },
        "id": "246f94a7",
        "outputId": "ad03f01b-5b42-4feb-d2ff-ee6ab526ee3e",
        "papermill": {
          "duration": 24.712964,
          "end_time": "2021-12-17T08:30:42.152592",
          "exception": false,
          "start_time": "2021-12-17T08:30:17.439628",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\r\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\r\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\r\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743be2f6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:31:16.341833Z",
          "iopub.status.busy": "2021-12-17T08:31:16.341161Z",
          "iopub.status.idle": "2021-12-17T08:31:34.231486Z",
          "shell.execute_reply": "2021-12-17T08:31:34.231988Z"
        },
        "id": "743be2f6",
        "outputId": "6a5a0917-919b-42fa-a26f-9ff601b97e6b",
        "papermill": {
          "duration": 35.359051,
          "end_time": "2021-12-17T08:31:34.232167",
          "exception": false,
          "start_time": "2021-12-17T08:30:58.873116",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87191b73da0344f4acaac8a68ad0c53a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c48610a40a64a18a887719118ca9fd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7f08e7e6b894bbea368f6f10fa69d57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60552cc09bf349268e4840626ade613b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b50b868",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:32:08.495428Z",
          "iopub.status.busy": "2021-12-17T08:32:08.494536Z",
          "iopub.status.idle": "2021-12-17T08:32:08.496477Z",
          "shell.execute_reply": "2021-12-17T08:32:08.496866Z"
        },
        "id": "1b50b868",
        "papermill": {
          "duration": 17.050999,
          "end_time": "2021-12-17T08:32:08.497010",
          "exception": false,
          "start_time": "2021-12-17T08:31:51.446011",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "sentences = data.text.values\n",
        "labels = data.category.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4857cfbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:32:42.560835Z",
          "iopub.status.busy": "2021-12-17T08:32:42.560145Z",
          "iopub.status.idle": "2021-12-17T08:32:42.563486Z",
          "shell.execute_reply": "2021-12-17T08:32:42.563906Z"
        },
        "id": "4857cfbd",
        "outputId": "0d660b1c-b805-4bf1-b1af-d4eee7e55c6e",
        "papermill": {
          "duration": 17.037764,
          "end_time": "2021-12-17T08:32:42.564051",
          "exception": false,
          "start_time": "2021-12-17T08:32:25.526287",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Tokenized:  ['могут', 'ли', 'в', 'рос', '##сель', '##хо', '##з', '##бан', '##ке', 'да', '##ть', 'в', 'зал', '##ог', 'но', '##рк', '##овых', 'ш', '##уб', 'пом', '##оги', '##те', 'по', '##жал', '##уи', '##ста']\n",
            "Token IDs:  [22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f7958c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:33:16.492818Z",
          "iopub.status.busy": "2021-12-17T08:33:16.487832Z",
          "iopub.status.idle": "2021-12-17T08:35:51.874960Z",
          "shell.execute_reply": "2021-12-17T08:35:51.875785Z"
        },
        "id": "73f7958c",
        "outputId": "e291d71e-6fc7-4da4-ab5e-25f082a41851",
        "papermill": {
          "duration": 172.099738,
          "end_time": "2021-12-17T08:35:51.876005",
          "exception": false,
          "start_time": "2021-12-17T08:32:59.776267",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Token IDs: [101, 22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294, 102]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9723ed36",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:36:25.814471Z",
          "iopub.status.busy": "2021-12-17T08:36:25.793683Z",
          "iopub.status.idle": "2021-12-17T08:36:25.817224Z",
          "shell.execute_reply": "2021-12-17T08:36:25.817665Z"
        },
        "id": "9723ed36",
        "outputId": "518813f0-96ed-41b8-fd9d-1bde3b14201c",
        "papermill": {
          "duration": 17.207657,
          "end_time": "2021-12-17T08:36:25.817834",
          "exception": false,
          "start_time": "2021-12-17T08:36:08.610177",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  97\n"
          ]
        }
      ],
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca8a7f78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:36:59.828659Z",
          "iopub.status.busy": "2021-12-17T08:36:59.827441Z",
          "iopub.status.idle": "2021-12-17T08:37:02.285372Z",
          "shell.execute_reply": "2021-12-17T08:37:02.285832Z"
        },
        "id": "ca8a7f78",
        "outputId": "928a73d2-c5b4-4198-abec-e40377ae6112",
        "papermill": {
          "duration": 19.637434,
          "end_time": "2021-12-17T08:37:02.285992",
          "exception": false,
          "start_time": "2021-12-17T08:36:42.648558",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 97 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# Let's set max_len to 97\n",
        "MAX_LEN = 97\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5027e0b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:37:36.050198Z",
          "iopub.status.busy": "2021-12-17T08:37:36.014563Z",
          "iopub.status.idle": "2021-12-17T08:37:59.974775Z",
          "shell.execute_reply": "2021-12-17T08:37:59.974241Z"
        },
        "id": "5027e0b1",
        "papermill": {
          "duration": 40.621274,
          "end_time": "2021-12-17T08:37:59.974961",
          "exception": false,
          "start_time": "2021-12-17T08:37:19.353687",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50dcbd6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:38:33.942563Z",
          "iopub.status.busy": "2021-12-17T08:38:33.941774Z",
          "iopub.status.idle": "2021-12-17T08:38:34.277896Z",
          "shell.execute_reply": "2021-12-17T08:38:34.276756Z"
        },
        "id": "f50dcbd6",
        "papermill": {
          "duration": 17.71172,
          "end_time": "2021-12-17T08:38:34.278046",
          "exception": false,
          "start_time": "2021-12-17T08:38:16.566326",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151b7711",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:39:08.268420Z",
          "iopub.status.busy": "2021-12-17T08:39:08.267385Z",
          "iopub.status.idle": "2021-12-17T08:39:11.182087Z",
          "shell.execute_reply": "2021-12-17T08:39:11.181552Z"
        },
        "id": "151b7711",
        "papermill": {
          "duration": 20.421829,
          "end_time": "2021-12-17T08:39:11.182224",
          "exception": false,
          "start_time": "2021-12-17T08:38:50.760395",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb823a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:39:45.449165Z",
          "iopub.status.busy": "2021-12-17T08:39:45.447530Z",
          "iopub.status.idle": "2021-12-17T08:39:45.449761Z",
          "shell.execute_reply": "2021-12-17T08:39:45.450165Z"
        },
        "id": "3cb823a0",
        "papermill": {
          "duration": 17.063162,
          "end_time": "2021-12-17T08:39:45.450309",
          "exception": false,
          "start_time": "2021-12-17T08:39:28.387147",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecea57b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:40:19.620326Z",
          "iopub.status.busy": "2021-12-17T08:40:19.619502Z",
          "iopub.status.idle": "2021-12-17T08:41:06.523549Z",
          "shell.execute_reply": "2021-12-17T08:41:06.524032Z"
        },
        "id": "2ecea57b",
        "outputId": "f7ac18bf-64f4-40c6-972f-522573f780f2",
        "papermill": {
          "duration": 63.789876,
          "end_time": "2021-12-17T08:41:06.524189",
          "exception": false,
          "start_time": "2021-12-17T08:40:02.734313",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51576380f0514dbcae377a1ac80396b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/641M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7239c78",
      "metadata": {
        "id": "f7239c78",
        "papermill": {
          "duration": 16.853209,
          "end_time": "2021-12-17T08:41:40.271166",
          "exception": false,
          "start_time": "2021-12-17T08:41:23.417957",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Проверяем что по параметрам все как в исходной тетрадке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379bf68a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:42:14.653390Z",
          "iopub.status.busy": "2021-12-17T08:42:14.652528Z",
          "iopub.status.idle": "2021-12-17T08:42:14.659015Z",
          "shell.execute_reply": "2021-12-17T08:42:14.658551Z"
        },
        "id": "379bf68a",
        "papermill": {
          "duration": 17.357784,
          "end_time": "2021-12-17T08:42:14.659143",
          "exception": false,
          "start_time": "2021-12-17T08:41:57.301359",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864e04c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:42:48.673410Z",
          "iopub.status.busy": "2021-12-17T08:42:48.672440Z",
          "iopub.status.idle": "2021-12-17T08:42:48.683300Z",
          "shell.execute_reply": "2021-12-17T08:42:48.682820Z"
        },
        "id": "864e04c9",
        "outputId": "73a87c8c-cdff-4e7b-a209-25f6a2665bbe",
        "papermill": {
          "duration": 17.168271,
          "end_time": "2021-12-17T08:42:48.683434",
          "exception": false,
          "start_time": "2021-12-17T08:42:31.515163",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d30eb5",
      "metadata": {
        "id": "77d30eb5",
        "papermill": {
          "duration": 17.460735,
          "end_time": "2021-12-17T08:43:22.872275",
          "exception": false,
          "start_time": "2021-12-17T08:43:05.411540",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Все как надо: в оригинале 28 классов, у нас 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28679cdd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:43:57.277389Z",
          "iopub.status.busy": "2021-12-17T08:43:57.276565Z",
          "iopub.status.idle": "2021-12-17T08:43:57.282383Z",
          "shell.execute_reply": "2021-12-17T08:43:57.281983Z"
        },
        "id": "28679cdd",
        "papermill": {
          "duration": 17.071969,
          "end_time": "2021-12-17T08:43:57.282510",
          "exception": false,
          "start_time": "2021-12-17T08:43:40.210541",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5bab78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:44:31.589539Z",
          "iopub.status.busy": "2021-12-17T08:44:31.588551Z",
          "iopub.status.idle": "2021-12-17T08:44:31.590492Z",
          "shell.execute_reply": "2021-12-17T08:44:31.591012Z"
        },
        "id": "fe5bab78",
        "papermill": {
          "duration": 17.43565,
          "end_time": "2021-12-17T08:44:31.591164",
          "exception": false,
          "start_time": "2021-12-17T08:44:14.155514",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "406d5f87",
      "metadata": {
        "id": "406d5f87",
        "papermill": {
          "duration": 17.001608,
          "end_time": "2021-12-17T08:45:05.578848",
          "exception": false,
          "start_time": "2021-12-17T08:44:48.577240",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "В оригинале считают accuracy, я переопределю функцию под F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53f9d10",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:45:39.606314Z",
          "iopub.status.busy": "2021-12-17T08:45:39.605393Z",
          "iopub.status.idle": "2021-12-17T08:45:39.607196Z",
          "shell.execute_reply": "2021-12-17T08:45:39.607586Z"
        },
        "id": "d53f9d10",
        "papermill": {
          "duration": 17.205316,
          "end_time": "2021-12-17T08:45:39.607755",
          "exception": false,
          "start_time": "2021-12-17T08:45:22.402439",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate f1 score of our predictions vs labels\n",
        "def flat_f1(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(pred_flat, labels_flat, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25625afd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:46:13.935430Z",
          "iopub.status.busy": "2021-12-17T08:46:13.934565Z",
          "iopub.status.idle": "2021-12-17T08:46:13.937054Z",
          "shell.execute_reply": "2021-12-17T08:46:13.936538Z"
        },
        "id": "25625afd",
        "papermill": {
          "duration": 17.4141,
          "end_time": "2021-12-17T08:46:13.937167",
          "exception": false,
          "start_time": "2021-12-17T08:45:56.523067",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb34080",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-17T08:46:47.556300Z",
          "iopub.status.busy": "2021-12-17T08:46:47.555253Z",
          "iopub.status.idle": "2021-12-17T11:01:17.761641Z",
          "shell.execute_reply": "2021-12-17T11:01:17.762188Z"
        },
        "id": "1eb34080",
        "outputId": "2a750fa4-86bd-41ec-8f19-efccb3603d66",
        "papermill": {
          "duration": 8087.266893,
          "end_time": "2021-12-17T11:01:17.762394",
          "exception": false,
          "start_time": "2021-12-17T08:46:30.495501",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:46.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:27.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:50.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:37.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:07:00.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:46.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:10.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:33.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:57.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:20.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:43.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:06.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:30.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:54.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:17.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:40.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:03.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:27.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:50.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:13.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:37.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:14:00.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:47.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:10.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:33.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:56.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:20.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:07.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:30.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:16.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:40.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:04.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:27.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:50.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:14.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:37.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:21:00.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:23.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:47.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:10.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:34.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:57.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:20.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:43.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:07.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:30.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:54.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:17.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:40.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:26:04.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:27.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:50.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:14.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:37.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:28:01.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:24.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:47.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:10.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:34.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:58.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:21.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:44.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:07.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:31.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:54.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:17.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:32:31\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.84\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:46.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:57.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:06.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:17.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:26.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:50.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:07:00.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:47.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:10.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:33.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:56.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:19.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:43.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:06.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:30.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:53.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:16.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:39.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:03.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:26.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:50.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:13.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:36.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:13:59.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:46.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:10.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:33.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:56.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:19.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:06.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:29.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:16.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:39.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:03.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:26.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:49.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:12.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:36.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:20:59.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:23.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:46.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:09.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:32.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:55.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:19.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:42.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:06.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:29.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:52.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:15.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:39.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:26:02.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:25.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:49.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:12.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:35.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:27:58.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:22.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:45.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:09.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:32.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:55.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:18.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:41.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:05.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:29.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:52.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:15.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:32:29\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:24.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:47.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:57.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:26.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:50.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:07:00.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:46.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:33.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:56.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:19.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:43.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:06.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:29.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:52.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:16.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:39.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:03.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:26.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:49.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:12.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:36.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:13:59.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:46.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:09.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:32.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:55.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:19.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:06.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:29.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:52.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:15.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:39.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:02.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:26.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:49.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:12.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:35.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:20:59.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:22.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:45.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:09.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:32.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:55.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:18.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:42.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:05.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:28.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:52.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:15.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:38.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:26:02.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:25.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:48.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:11.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:35.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:27:58.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:21.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:45.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:08.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:31.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:54.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:18.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:41.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:05.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:28.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:51.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:14.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:32:28\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:46.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:06.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:29.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:26.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:49.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:12.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:06:59.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:46.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:32.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:55.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:19.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:42.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:05.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:29.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:52.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:15.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:38.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:01.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:25.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:48.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:11.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:35.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:13:58.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:21.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:44.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:07.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:31.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:54.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:18.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:41.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:04.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:27.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:50.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:14.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:37.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:00.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:24.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:47.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:10.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:33.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:20:57.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:20.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:43.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:07.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:30.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:53.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:16.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:40.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:03.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:26.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:49.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:12.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:36.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:25:59.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:22.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:46.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:09.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:32.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:27:55.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:18.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:42.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:05.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:29.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:52.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:15.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:38.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:01.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:24.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:48.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:11.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:32:25\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_f1 = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate f1 score for this batch of test sentences.\n",
        "        tmp_eval_f1 = flat_f1(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total f1 score.\n",
        "        eval_f1 += tmp_eval_f1\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final F1 score for this validation run.\n",
        "    print(\"  F1 score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e80737",
      "metadata": {
        "id": "84e80737",
        "papermill": {
          "duration": 16.308595,
          "end_time": "2021-12-17T11:01:51.239518",
          "exception": false,
          "start_time": "2021-12-17T11:01:34.930923",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 10996.020736,
      "end_time": "2021-12-17T11:02:11.429492",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-12-17T07:58:55.408756",
      "version": "2.3.3"
    },
    "colab": {
      "name": "LSTM_attention_BERT_hw3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}