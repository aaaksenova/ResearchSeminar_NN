{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaaksenova/ResearchSeminar_NN/blob/change/LSTM_attention_BERT_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91f7818f",
        "outputId": "d2e163b6-6768-449a-aa04-274dab173eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ],
      "id": "91f7818f"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d6b80f4",
        "outputId": "4be6c525-6caf-4f44-cd7c-baa01a6f50d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "id": "7d6b80f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ea1b1e6"
      },
      "source": [
        "# Скачиваем данные"
      ],
      "id": "5ea1b1e6"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6b73bb1f"
      },
      "outputs": [],
      "source": [
        "# Добавила сид\n",
        "import random\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "id": "6b73bb1f"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24f860b3",
        "outputId": "50ba0871-43d2-460d-fb22-e48cdd823a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-19 06:54:46--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   147MB/s    in 0.2s    \n",
            "\n",
            "2021-12-19 06:54:47 (147 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ],
      "id": "24f860b3"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0653a703"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ],
      "id": "0653a703"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cd9b728",
        "outputId": "99268731-c984-4db6-ddc3-e8a5380e6d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec 19 06:54 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ],
      "id": "7cd9b728"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d1c96e52"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "d1c96e52"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bee6fe51"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ],
      "id": "bee6fe51"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "daf5e50e",
        "outputId": "b9e3876f-bc0a-444a-be44-0795ebc104f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1f6bbfd5-f87e-485d-a018-7f136425d78e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f6bbfd5-f87e-485d-a018-7f136425d78e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f6bbfd5-f87e-485d-a018-7f136425d78e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f6bbfd5-f87e-485d-a018-7f136425d78e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data"
      ],
      "id": "daf5e50e"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a363fefb",
        "outputId": "915fce82-9df9-4eab-dbe1-be495b707175"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ],
      "id": "a363fefb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f87dfcf"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ],
      "id": "1f87dfcf"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9012b225",
        "outputId": "7c4e89e7-a54b-43cc-f551-1f336bda6eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-19 06:54:48--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  16.1MB/s    in 79s     \n",
            "\n",
            "2021-12-19 06:56:08 (15.7 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ],
      "id": "9012b225"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99a841eb",
        "outputId": "ef561ccc-5cea-4095-f5ea-5aab7914e1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec 19 06:54 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ],
      "id": "99a841eb"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8763b456"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "id": "8763b456"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aa66f9da"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ],
      "id": "aa66f9da"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "183e5237",
        "outputId": "d7088878-0392-40b2-eccc-86df6df1a92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:02<00:00, 88114.09it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "id": "183e5237"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "95b3cd93"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "id": "95b3cd93"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "40fc93b2",
        "outputId": "4d090b8c-ab0e-4d1d-cf86-d4865192840d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5c41aa4950>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ],
      "id": "40fc93b2"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "45cbeca6",
        "outputId": "af1338f1-d1e1-4088-d2dc-39379cdc1b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ],
      "id": "45cbeca6"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a7c8cae",
        "outputId": "3b097d8c-df2b-43f1-e3d4-7e823bbf7b16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(word2freq)"
      ],
      "id": "9a7c8cae"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "977be5eb",
        "outputId": "a62cd7a7-b21d-4569-fcf6-affd553c053f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ],
      "id": "977be5eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62fe1085"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ],
      "id": "62fe1085"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e3c5f026"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ],
      "id": "e3c5f026"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3799585",
        "outputId": "80f34684-d0d8-4391-f7d6-d1ffd14bed23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:19<00:00, 25259.95it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ],
      "id": "b3799585"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "536236b7",
        "outputId": "e5b1c053-f1f3-47e0-c303-ce0034a44c52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(word2index)"
      ],
      "id": "536236b7"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdcc1ea9",
        "outputId": "b78319a6-dece-4750-c3a0-e422be17e79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "id": "fdcc1ea9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eeb8966"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ],
      "id": "9eeb8966"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5c9d9dc5"
      },
      "outputs": [],
      "source": [
        "import torch"
      ],
      "id": "5c9d9dc5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c63390f3"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ],
      "id": "c63390f3"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a1373bda"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ],
      "id": "a1373bda"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "f2e537dc"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ],
      "id": "f2e537dc"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa9c6eaf",
        "outputId": "fe59b0e2-387c-489c-bb41-b0e0a2f2298f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 823 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ],
      "id": "fa9c6eaf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25ef4f2"
      },
      "source": [
        "# А что GPU?"
      ],
      "id": "a25ef4f2"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26e7ddd5",
        "outputId": "ad4dac52-0b6b-4ae7-c386-d4c7a1e951ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ],
      "id": "26e7ddd5"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2b36a0cf"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ],
      "id": "2b36a0cf"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "c7d132df"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ],
      "id": "c7d132df"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "a51babe1"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ],
      "id": "a51babe1"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15c94690",
        "outputId": "5685a4b6-d54a-460a-caf1-e37a1521369a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 27.6 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ],
      "id": "15c94690"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d504c5e0"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ],
      "id": "d504c5e0"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "40d82100"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ],
      "id": "40d82100"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eb4e69b"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ],
      "id": "8eb4e69b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c0e0377"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ],
      "id": "1c0e0377"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "632b809a"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ],
      "id": "632b809a"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6eb7e40a"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ],
      "id": "6eb7e40a"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a035a66",
        "outputId": "c71dc961-50b5-46ae-d9be-e9881dd0fa50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "pred.shape"
      ],
      "id": "4a035a66"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0e8cbb55"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ],
      "id": "0e8cbb55"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7821f1bf",
        "outputId": "2fcaa84c-bb92-43b6-990e-ec88da76f1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ],
      "id": "7821f1bf"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b6bceeb",
        "outputId": "f7361d88-831b-47c9-e2e4-7ef0b1a81ba3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ],
      "id": "9b6bceeb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc2d37b7"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ],
      "id": "bc2d37b7"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ef7d330",
        "outputId": "37ddb30d-589b-440e-d955-8378ae8a613d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "x.shape"
      ],
      "id": "8ef7d330"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b0cb89"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ],
      "id": "d5b0cb89"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "59d0e790"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ],
      "id": "59d0e790"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "b6ec930c"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ],
      "id": "b6ec930c"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a201b9",
        "outputId": "dc02c0c3-ae3d-4fc6-d56e-0337c17e758e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ],
      "id": "76a201b9"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4085edea",
        "outputId": "e33f6784-44a9-404f-8290-d829706f8530"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ],
      "id": "4085edea"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d794117",
        "outputId": "63201db1-f36b-4ea6-847d-b360cc5c5de0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ],
      "id": "6d794117"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5162850e"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ],
      "id": "5162850e"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "c9a92837"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "id": "c9a92837"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53c24ed4",
        "outputId": "f7448b48-8a7c-4423-ae1e-684adb1c7cc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "'UNK' in word2index"
      ],
      "id": "53c24ed4"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "6996b3b3",
        "outputId": "201b4684-6b58-4a60-8e61-6554c58b9859"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-64fe8f83-702e-4354-8dda-43b47bcf97a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64fe8f83-702e-4354-8dda-43b47bcf97a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64fe8f83-702e-4354-8dda-43b47bcf97a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64fe8f83-702e-4354-8dda-43b47bcf97a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "data.head()"
      ],
      "id": "6996b3b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a8537e9"
      },
      "source": [
        "# Замапим категории в индексы"
      ],
      "id": "3a8537e9"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "b1a7d27d"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ],
      "id": "b1a7d27d"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec7d9295",
        "outputId": "5bdda9b1-7ccb-41c6-8be4-6d9372b8ffc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'food': 4, 'law': 1, 'love': 2, 'relax': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "cat_mapper"
      ],
      "id": "ec7d9295"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "473d9fa0"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ],
      "id": "473d9fa0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7184959d"
      },
      "source": [
        "# Читалка данных"
      ],
      "id": "7184959d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8af8b5e4"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ],
      "id": "8af8b5e4"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "f5d5ce38"
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "id": "f5d5ce38"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "703be945"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "id": "703be945"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7db8be9e",
        "outputId": "ca97842e-2628-4003-9c42-aa604a30dcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:03<00:00, 67243.36it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 73906.33it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ],
      "id": "7db8be9e"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "8c298bc7"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "id": "8c298bc7"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce6acf21",
        "outputId": "efe400c0-beeb-41d9-b30a-8d8a2f680d68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  115,    56,   160,  ...,     0,     0,     0],\n",
              "        [   46, 27846,    41,  ...,     0,     0,     0],\n",
              "        [97006, 35191,    14,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [   24,   152, 64214,  ...,     0,     0,     0],\n",
              "        [ 9867,    21,  5438,  ...,     0,     0,     0],\n",
              "        [ 5229,   695,    10,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "x"
      ],
      "id": "ce6acf21"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "023bf397",
        "outputId": "c33feaf7-9387-4ba4-abe3-0e93618a389f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 4, 2, 3, 2, 0, 4, 4, 2, 3, 1, 3, 1, 3, 3, 3, 0, 1, 3, 0, 4, 3, 0,\n",
              "        0, 1, 0, 1, 2, 1, 1, 4, 0, 3, 1, 0, 2, 1, 1, 4, 1, 2, 1, 0, 1, 0, 1, 3,\n",
              "        4, 2, 1, 2, 0, 1, 1, 1, 1, 1, 4, 3, 0, 3, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "y"
      ],
      "id": "023bf397"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef4656c1"
      },
      "source": [
        "# Обучить нейронку"
      ],
      "id": "ef4656c1"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "b10182a3"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "      def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "\n",
        "            super().__init__()\n",
        "\n",
        "            self.n = n\n",
        "\n",
        "            self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "            self.LSTM = torch.nn.LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "            # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "\n",
        "            self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "            self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "            self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "            self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "            self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,)) # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "            self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "            self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "\n",
        "            self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          x_emb = self.emb_layer(x) #примените эмбеддинги \n",
        "          # транспонируйте тензор для лстм как было описано выше\n",
        "          x_lstm, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "\n",
        "          x_q = self.q_proj(x_lstm) # применим линейные преобразования для селф-эттеншена\n",
        "          x_k = self.k_proj(x_lstm)\n",
        "          x_v = self.v_proj(x_lstm)\n",
        "\n",
        "          att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "          # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "          # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "          att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "          attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "          x_att = attention_vectors.transpose(2, 1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "          x_cnn3 = self.cnn_3gr(x_att)\n",
        "          x_cnn4 = self.cnn_4gr(x_att)\n",
        "          x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "          frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "          sc, _ = x_cnn4.max(dim= -1,)\n",
        "          thr, _ = x_cnn5.max(dim= -1,)\n",
        "\n",
        "          x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "\n",
        "          x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "          x = self.relu(x)    \n",
        "          x = self.linear_2(x)\n",
        "\n",
        "          return x"
      ],
      "id": "b10182a3"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ac5f6314"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_with_att(vectors, n_classes)"
      ],
      "id": "ac5f6314"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "b55c72eb",
        "outputId": "bbdf6cbc-8c40-4556-ba8b-7573c7e1d590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ],
      "id": "b55c72eb"
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "Hr6al45zfXkL"
      },
      "id": "Hr6al45zfXkL",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "e3ec4648"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ],
      "id": "e3ec4648"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "66ef3617",
        "outputId": "076b59c2-d437-4d1f-8c80-94adfabe035b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "pred.shape"
      ],
      "id": "66ef3617"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "b97a0657"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "id": "b97a0657"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ed973107"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "id": "ed973107"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "3c37b34c",
        "outputId": "6e6f4570-d34a-4814-f091-fe116f30af94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:27<00:00, 1029.74it/s, train_loss=0.476]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.565, test - 0.466\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:26<00:00, 1036.70it/s, train_loss=0.441]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.452, test - 0.447\n",
            "F1 test - 0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:26<00:00, 1038.60it/s, train_loss=0.417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.426, test - 0.439\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:26<00:00, 1037.19it/s, train_loss=0.395]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.403, test - 0.442\n",
            "F1 test - 0.842\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "id": "3c37b34c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6625b8f9"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ],
      "id": "6625b8f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7456c2b"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов. ✅\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ],
      "id": "d7456c2b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a949bf3"
      },
      "source": [
        "Какие эксперименты я ставила:\n",
        "\n",
        "1. Weight decay в Адаме – не улучшило\n",
        "2. Больше линейных слоев и дропаута – вообще перестало нормально учиться\n",
        "3. Стала менять функцию активации на что-то более фэнси: пробовала LeakyReLU, SiLU, остановилась на Parametric ReLU, она и решила задачку с улучшением качества\n"
      ],
      "id": "3a949bf3"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "cf089b37"
      },
      "outputs": [],
      "source": [
        "class model_upd(torch.nn.Module):\n",
        "      def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "\n",
        "            super().__init__()\n",
        "\n",
        "            self.n = n\n",
        "\n",
        "            self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "            self.LSTM = torch.nn.LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "            # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "\n",
        "            self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "            self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "            self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "            self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "            self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,)) # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "            self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "            self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "\n",
        "            self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n",
        "            self.linear_added = torch.nn.Linear(in_features=256, out_features=256, bias=True) \n",
        "            self.relu = torch.nn.PReLU()\n",
        "            self.dropout = torch.nn.Dropout(p=0.5)\n",
        "            self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          x_emb = self.emb_layer(x) #примените эмбеддинги \n",
        "          # транспонируйте тензор для лстм как было описано выше\n",
        "          x_lstm, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "\n",
        "          x_q = self.q_proj(x_lstm) # применим линейные преобразования для селф-эттеншена\n",
        "          x_k = self.k_proj(x_lstm)\n",
        "          x_v = self.v_proj(x_lstm)\n",
        "\n",
        "          att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "          # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "          # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "          att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "          attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "          x_att = attention_vectors.transpose(2, 1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "          x_cnn3 = self.cnn_3gr(x_att)\n",
        "          x_cnn4 = self.cnn_4gr(x_att)\n",
        "          x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "          frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "          sc, _ = x_cnn4.max(dim= -1,)\n",
        "          thr, _ = x_cnn5.max(dim= -1,)\n",
        "\n",
        "          x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "\n",
        "          x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "          x = self.dropout(self.relu(x))      \n",
        "          x = self.linear_2(x)\n",
        "\n",
        "          return x"
      ],
      "id": "cf089b37"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "76d1295b"
      },
      "outputs": [],
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ],
      "id": "76d1295b"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "dd821be0"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_upd(vectors, n_classes)"
      ],
      "id": "dd821be0"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "2b7133d8"
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "model = model_upd(vectors, n_classes)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters()) #, weight_decay=0.0001)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "id": "2b7133d8"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "00dad1be",
        "outputId": "9793c3ee-c24f-492b-b0af-bf39188f92a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:24<00:00, 1045.30it/s, train_loss=0.487]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.588, test - 0.462\n",
            "F1 test - 0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:22<00:00, 1057.10it/s, train_loss=0.448]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.460, test - 0.444\n",
            "F1 test - 0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:21<00:00, 1060.47it/s, train_loss=0.424]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.433, test - 0.443\n",
            "F1 test - 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:22<00:00, 1054.73it/s, train_loss=0.403]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.411, test - 0.442\n",
            "F1 test - 0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [03:22<00:00, 1059.29it/s, train_loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.391, test - 0.456\n",
            "F1 test - 0.839\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "id": "00dad1be"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "d8d5d29e"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ExponentialLR"
      ],
      "id": "d8d5d29e"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "b4736fc4"
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_upd(vectors, n_classes)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters()) #, weight_decay=0.0001)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.7)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "id": "b4736fc4"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69a68430",
        "outputId": "fae4bc95-070b-4880-896b-0473ef0a8616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:24<00:00, 1046.02it/s, train_loss=0.486]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.588, test - 0.471\n",
            "F1 test - 0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:24<00:00, 1048.91it/s, train_loss=0.444]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.454, test - 0.453\n",
            "F1 test - 0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:24<00:00, 1044.82it/s, train_loss=0.416]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.426, test - 0.440\n",
            "F1 test - 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:25<00:00, 1043.74it/s, train_loss=0.395]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.405, test - 0.433\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [03:25<00:00, 1043.03it/s, train_loss=0.376]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.388, test - 0.434\n",
            "F1 test - 0.843\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "\n",
        "    scheduler.step()    \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "id": "69a68430"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0212426"
      },
      "source": [
        "# BERT"
      ],
      "id": "a0212426"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "246f94a7",
        "outputId": "ad03f01b-5b42-4feb-d2ff-ee6ab526ee3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\r\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\r\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\r\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ],
      "id": "246f94a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "743be2f6",
        "outputId": "6a5a0917-919b-42fa-a26f-9ff601b97e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87191b73da0344f4acaac8a68ad0c53a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c48610a40a64a18a887719118ca9fd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7f08e7e6b894bbea368f6f10fa69d57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60552cc09bf349268e4840626ade613b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ],
      "id": "743be2f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b50b868"
      },
      "outputs": [],
      "source": [
        "sentences = data.text.values\n",
        "labels = data.category.values"
      ],
      "id": "1b50b868"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4857cfbd",
        "outputId": "0d660b1c-b805-4bf1-b1af-d4eee7e55c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Tokenized:  ['могут', 'ли', 'в', 'рос', '##сель', '##хо', '##з', '##бан', '##ке', 'да', '##ть', 'в', 'зал', '##ог', 'но', '##рк', '##овых', 'ш', '##уб', 'пом', '##оги', '##те', 'по', '##жал', '##уи', '##ста']\n",
            "Token IDs:  [22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "id": "4857cfbd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73f7958c",
        "outputId": "e291d71e-6fc7-4da4-ab5e-25f082a41851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Token IDs: [101, 22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294, 102]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "id": "73f7958c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9723ed36",
        "outputId": "518813f0-96ed-41b8-fd9d-1bde3b14201c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  97\n"
          ]
        }
      ],
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "id": "9723ed36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca8a7f78",
        "outputId": "928a73d2-c5b4-4198-abec-e40377ae6112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 97 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# Let's set max_len to 97\n",
        "MAX_LEN = 97\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "id": "ca8a7f78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5027e0b1"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "id": "5027e0b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f50dcbd6"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "id": "f50dcbd6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "151b7711"
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "id": "151b7711"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cb823a0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "id": "3cb823a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ecea57b",
        "outputId": "f7ac18bf-64f4-40c6-972f-522573f780f2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51576380f0514dbcae377a1ac80396b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/641M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "id": "2ecea57b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7239c78"
      },
      "source": [
        "Проверяем что по параметрам все как в исходной тетрадке"
      ],
      "id": "f7239c78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "379bf68a"
      },
      "outputs": [],
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ],
      "id": "379bf68a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "864e04c9",
        "outputId": "73a87c8c-cdff-4e7b-a209-25f6a2665bbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "id": "864e04c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77d30eb5"
      },
      "source": [
        "Все как надо: в оригинале 28 классов, у нас 5"
      ],
      "id": "77d30eb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28679cdd"
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "id": "28679cdd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe5bab78"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "id": "fe5bab78"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "406d5f87"
      },
      "source": [
        "В оригинале считают accuracy, я переопределю функцию под F1"
      ],
      "id": "406d5f87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d53f9d10"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate f1 score of our predictions vs labels\n",
        "def flat_f1(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(pred_flat, labels_flat, average='micro')"
      ],
      "id": "d53f9d10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25625afd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "id": "25625afd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eb34080",
        "outputId": "2a750fa4-86bd-41ec-8f19-efccb3603d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:46.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:27.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:50.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:37.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:07:00.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:46.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:10.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:33.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:57.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:20.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:43.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:06.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:30.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:54.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:17.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:40.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:03.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:27.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:50.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:13.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:37.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:14:00.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:47.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:10.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:33.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:56.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:20.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:07.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:30.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:16.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:40.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:04.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:27.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:50.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:14.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:37.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:21:00.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:23.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:47.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:10.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:34.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:57.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:20.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:43.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:07.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:30.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:54.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:17.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:40.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:26:04.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:27.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:50.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:14.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:37.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:28:01.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:24.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:47.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:10.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:34.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:58.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:21.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:44.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:07.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:31.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:54.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:17.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:32:31\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.84\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:46.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:57.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:06.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:17.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:26.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:50.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:07:00.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:47.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:10.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:33.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:56.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:19.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:43.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:06.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:30.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:53.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:16.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:39.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:03.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:26.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:50.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:13.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:36.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:13:59.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:46.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:10.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:33.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:56.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:19.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:06.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:29.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:16.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:39.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:03.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:26.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:49.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:12.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:36.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:20:59.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:23.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:46.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:09.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:32.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:55.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:19.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:42.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:06.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:29.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:52.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:15.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:39.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:26:02.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:25.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:49.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:12.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:35.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:27:58.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:22.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:45.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:09.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:32.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:55.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:18.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:41.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:05.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:29.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:52.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:15.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:32:29\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:24.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:47.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:57.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:26.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:50.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:07:00.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:46.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:33.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:56.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:19.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:43.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:06.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:29.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:52.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:16.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:39.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:03.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:26.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:49.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:12.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:36.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:13:59.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:46.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:09.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:32.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:55.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:19.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:06.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:29.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:52.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:15.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:39.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:02.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:26.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:49.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:12.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:35.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:20:59.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:22.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:45.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:09.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:32.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:55.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:18.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:42.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:05.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:28.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:52.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:15.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:38.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:26:02.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:25.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:48.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:11.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:35.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:27:58.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:21.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:45.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:08.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:31.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:54.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:18.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:41.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:05.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:28.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:51.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:14.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:32:28\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:46.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:03:06.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:03:29.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:05:26.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:05:49.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:06:12.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:06:59.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:07:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:07:46.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:08:32.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:08:55.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:09:19.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:09:42.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:10:05.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:10:29.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:10:52.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:11:15.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:11:38.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:12:01.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:12:25.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:12:48.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:13:11.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:13:35.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:13:58.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:14:21.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:14:44.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:15:07.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:15:31.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:15:54.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:16:18.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:16:41.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:17:04.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:17:27.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:17:50.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:18:14.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:18:37.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:19:00.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:19:24.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:19:47.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:20:10.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:20:33.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:20:57.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:21:20.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:21:43.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:22:07.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:22:30.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:22:53.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:23:16.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:23:40.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:24:03.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:24:26.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:24:49.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:25:12.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:25:36.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:25:59.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:26:22.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:26:46.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:27:09.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:27:32.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:27:55.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:28:18.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:28:42.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:29:05.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:29:29.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:29:52.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:30:15.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:30:38.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:31:01.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:31:24.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:31:48.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:32:11.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:32:25\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:01:09\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_f1 = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate f1 score for this batch of test sentences.\n",
        "        tmp_eval_f1 = flat_f1(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total f1 score.\n",
        "        eval_f1 += tmp_eval_f1\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final F1 score for this validation run.\n",
        "    print(\"  F1 score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "id": "1eb34080"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84e80737"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "84e80737"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_attention_BERT_hw3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 10996.020736,
      "end_time": "2021-12-17T11:02:11.429492",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-12-17T07:58:55.408756",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}